{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library yang kalian butuhkan\n",
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from scipy.stats import entropy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buat struktur folder dataset sebagai berikut:\n",
    "```\n",
    ".\n",
    "└──dataset\n",
    "    ├── label1\n",
    "\t├── image1.jpg\n",
    "\t├── image2.jpg\n",
    "\t└── image3.jpg\n",
    "    ├── label2\n",
    "    └── label3\n",
    "    └── dst...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "file_name = []\n",
    "for sub_folder in os.listdir(\"dataset\\\\\"):\n",
    "    sub_folder_files = os.listdir(os.path.join(\"dataset\\\\\", sub_folder))\n",
    "    for i, filename in enumerate(sub_folder_files):\n",
    "        img_path = os.path.join(\"dataset\\\\\", sub_folder, filename)\n",
    "        img = cv.imread(img_path)\n",
    "        img = img.astype(np.uint8)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "        data.append(img)\n",
    "        labels.append(sub_folder)\n",
    "        name = os.path.splitext(filename)[0]\n",
    "        file_name.append(filename)\n",
    "        \n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Augmentation Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melakukan augmentasi data\n",
    "data_augmented = []\n",
    "labels_augmented = []\n",
    "paths_augmented = []\n",
    "file_name_augmented = []\n",
    "for i in range(len(data)):\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data sebelum augmentasi: \", len(data))\n",
    "print(\"Data setelah augmentasi: \", len(data_augmented))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Preprocessing Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image, target_size):\n",
    "    pass\n",
    "\n",
    "def prepro1():\n",
    "    pass\n",
    "\n",
    "def prepro2():\n",
    "    pass\n",
    "\n",
    "def prepro3():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pada bagian ini bisa gunakan data yang sebelum augmentasi atau setelah augmentasi\n",
    "dataPreprocessed = []\n",
    "for i in range(len(data)): # Loop through each image and do preprocessing\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glcm(image, derajat):\n",
    "    if derajat == 0:\n",
    "        angles = [0]\n",
    "    elif derajat == 45:\n",
    "        angles = [np.pi / 4]\n",
    "    elif derajat == 90:\n",
    "        angles = [np.pi / 2]\n",
    "    elif derajat == 135:\n",
    "        angles = [3 * np.pi / 4]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid angle. It should be one of the following: 0, 45, 90, 135.\")\n",
    "    \n",
    "    # mengembalikan matrix glcm dari image\n",
    "    glcm = graycomatrix(image, [1], angles, 256, symmetric=True, normed=True)\n",
    "    return glcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(matriks):\n",
    "\treturn graycoprops(matriks, 'correlation')[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissimilarity(matriks):\n",
    "    return graycoprops(matriks, 'dissimilarity')[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homogenity(matriks):\n",
    "    return graycoprops(matriks, 'homogeneity')[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast(matriks):\n",
    "    return graycoprops(matriks, 'contrast')[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ASM(matriks):\n",
    "    return graycoprops(matriks, 'ASM')[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy(matriks):\n",
    "    return graycoprops(matriks, 'energy')[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropyGlcm(matriks):\n",
    "    return entropy(matriks.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Derajat0 = []\n",
    "Derajat45 = []\n",
    "Derajat90 = []\n",
    "Derajat135 = []\n",
    "for i in range(len(dataPreprocessed)):\n",
    "    D0 = glcm(dataPreprocessed[i], 0)\n",
    "    D45 = glcm(dataPreprocessed[i], 45)\n",
    "    D90 = glcm(dataPreprocessed[i], 90)\n",
    "    D135 = glcm(dataPreprocessed[i], 135)\n",
    "    Derajat0.append(D0)\n",
    "    Derajat45.append(D45)\n",
    "    Derajat90.append(D90)\n",
    "    Derajat135.append(D135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kontras0, Kontras45, Kontras90, Kontras135 = [], [], [], []\n",
    "dissimilarity0, dissimilarity45, dissimilarity90, dissimilarity135 =  [], [], [], []\n",
    "homogenity0, homogenity45, homogenity90, homogenity135 = [], [], [], []\n",
    "entropy0, entropy45, entropy90, entropy135 =  [], [], [], []\n",
    "ASM0, ASM45, ASM90, ASM135 =  [], [], [], []\n",
    "energy0, energy45, energy90, energy135 =  [], [], [], []\n",
    "correlation0, correlation45, correlation90, correlation135 = [], [], [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataPreprocessed)):\n",
    "    C0 = correlation(Derajat0[i])\n",
    "    correlation0.append(C0)\n",
    "    C45 = correlation(Derajat45[i])\n",
    "    correlation45.append(C45)\n",
    "    C90 = correlation(Derajat90[i])\n",
    "    correlation90.append(C90)\n",
    "    C135 = correlation(Derajat135[i])\n",
    "    correlation135.append(C135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    K0 = contrast(Derajat0[i])\n",
    "    K45 = contrast(Derajat45[i])\n",
    "    K90 = contrast(Derajat90[i])\n",
    "    K135 = contrast(Derajat135[i])\n",
    "    Kontras0.append(K0)\n",
    "    Kontras45.append(K45)\n",
    "    Kontras90.append(K90)\n",
    "    Kontras135.append(K135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    Dis0 = dissimilarity(Derajat0[i])\n",
    "    Dis45 = dissimilarity(Derajat45[i])\n",
    "    Dis90 = dissimilarity(Derajat90[i])\n",
    "    Dis135 = dissimilarity(Derajat135[i])\n",
    "    dissimilarity0.append(Dis0)\n",
    "    dissimilarity45.append(Dis45)\n",
    "    dissimilarity90.append(Dis90)\n",
    "    dissimilarity135.append(Dis135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    H0 = homogenity(Derajat0[i])\n",
    "    H45 = homogenity(Derajat45[i])\n",
    "    H90 = homogenity(Derajat90[i])\n",
    "    H135 = homogenity(Derajat135[i])\n",
    "    homogenity0.append(H0)\n",
    "    homogenity45.append(H45)\n",
    "    homogenity90.append(H90)\n",
    "    homogenity135.append(H135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):  \n",
    "    E0 = entropyGlcm(Derajat0[i])\n",
    "    E45 = entropyGlcm(Derajat45[i])\n",
    "    E90 = entropyGlcm(Derajat90[i])\n",
    "    E135 = entropyGlcm(Derajat135[i])\n",
    "    entropy0.append(E0)\n",
    "    entropy45.append(E45)\n",
    "    entropy90.append(E90)\n",
    "    entropy135.append(E135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    A0 = ASM(Derajat0[i])\n",
    "    A45 = ASM(Derajat45[i])\n",
    "    A90 = ASM(Derajat90[i])\n",
    "    A135 = ASM(Derajat135[i])\n",
    "    ASM0.append(A0)\n",
    "    ASM45.append(A45)\n",
    "    ASM90.append(A90)\n",
    "    ASM135.append(A135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    ER0 = energy(Derajat0[i])\n",
    "    ER45 = energy(Derajat45[i])\n",
    "    ER90 = energy(Derajat90[i])\n",
    "    ER135 = energy(Derajat135[i])\n",
    "    energy0.append(ER0)\n",
    "    energy45.append(ER45)\n",
    "    energy90.append(ER90)\n",
    "    energy135.append(ER135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the extraction's results to CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTable = {'Filename': file_name, 'Label': labels,\n",
    "        'Contrast0': Kontras0, 'Contrast45': Kontras45, 'Contrast90': Kontras90, 'Contrast135': Kontras135,\n",
    "        'Homogeneity0': homogenity0, 'Homogeneity45': homogenity45, 'Homogeneity90': homogenity90, 'Homogeneity135': homogenity135,\n",
    "        'Dissimilarity0': dissimilarity0, 'Dissimilarity45': dissimilarity45, 'Dissimilarity90': dissimilarity90, 'Dissimilarity135': dissimilarity135,\n",
    "        'Entropy0': entropy0, 'Entropy45': entropy45, 'Entropy90': entropy90, 'Entropy135': entropy135,\n",
    "        'ASM0': ASM0, 'ASM45': ASM45, 'ASM90': ASM90, 'ASM135': ASM135,\n",
    "        'Energy0': energy0, 'Energy45': energy45, 'Energy90': energy90, 'Energy135': energy135,\n",
    "        'Correlation0': correlation0, 'Correlation45': correlation45, 'Correlation90': correlation90, 'Correlation135': correlation135,\n",
    "        }\n",
    "df = pd.DataFrame(dataTable)\n",
    "df.to_csv('hasil_ekstraksi_1.csv', index=False)\n",
    "\n",
    "hasilEkstrak = pd.read_csv('hasil_ekstraksi_1.csv')\n",
    "hasilEkstrak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pada bagian seleksi fitur ini bisa menggunakan metode seperti\n",
    "- PCA\n",
    "- LDA\n",
    "- t-SNE\n",
    "- Chi-square\n",
    "- ANOVA\n",
    "- Autoencoder\n",
    "- correlation\n",
    "- dll\n",
    "\n",
    "berikut contoh menggunakan correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung korelasi\n",
    "correlation = hasilEkstrak.drop(columns=['Label','Filename']).corr()\n",
    "\n",
    "# Menyaring fitur yang memiliki korelasi absolut lebih dari 0.95 dengan label\n",
    "threshold = 0.95 # atur threshold ini untuk menentukan seberapa besar korelasi yang ingin disaring\n",
    "selectionFeature = []\n",
    "columns = np.full((correlation.shape[0],), True, dtype=bool)\n",
    "for i in range(correlation.shape[0]):\n",
    "\tfor j in range(i+1, correlation.shape[0]):\n",
    "\t\tif correlation.iloc[i,j] >= threshold:\n",
    "\t\t\tif columns[j]:\n",
    "\t\t\t\tcolumns[j] = False\n",
    "select = hasilEkstrak.drop(columns=['Label','Filename']).columns[columns]\n",
    "x_new = hasilEkstrak[select]\n",
    "x_new\n",
    "y = hasilEkstrak['Label']\n",
    "plt.figure(figsize=(17,17))\n",
    "sns.heatmap(x_new.corr(), annot=True, cmap='Blues', fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ubah bagian test_size sesuai kebutuhan\n",
    "# 0.3 = 30% data untuk testing (train/test 70/30)\n",
    "# 0.2 = 20% data untuk testing (train/test 80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_new, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "berikut metode normalisasi yang bisa digunakan:\n",
    "- Min-Max Scaling\n",
    "- Standardization (Z-score)\n",
    "- Robust Scaling\n",
    "- MaxAbsScaler\n",
    "- dll\n",
    "\n",
    "berikut contoh menggunakan Standardization (Z-score):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisasi mean std\n",
    "X_test = (X_test - X_train.mean()) / X_train.std()\n",
    "X_train = (X_train - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateClassificationReport(y_true, y_pred):\n",
    "\tprint(classification_report(y_true, y_pred))\n",
    "\tprint(confusion_matrix(y_true, y_pred))\n",
    "\tprint('Accuracy:', accuracy_score(y_true, y_pred))\n",
    "\n",
    "# Define classifiers\n",
    "rf = RandomForestClassifier(n_estimators=5, random_state=42)\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest Classifier\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model with the training set\n",
    "print(\"------Training Set------\")\n",
    "y_pred = rf.predict(X_train)\n",
    "generateClassificationReport( y_train, y_pred)\n",
    "\n",
    "# Make predictions and evaluate the model with the testing set\n",
    "print(\"\\n------Testing Set------\")\n",
    "y_pred = rf.predict(X_test)\n",
    "generateClassificationReport( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM Classifier\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model with the training set\n",
    "print(\"\\n------Training Set------\")\n",
    "y_pred = svm.predict(X_train)\n",
    "generateClassificationReport( y_train, y_pred)\n",
    "\n",
    "# Make predictions and evaluate the model with the testing set\n",
    "print(\"\\n------Testing Set------\")\n",
    "y_pred = svm.predict(X_test)\n",
    "generateClassificationReport( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN Classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model with the training set\n",
    "print(\"\\n------Training Set------\")\n",
    "y_pred = knn.predict(X_train)\n",
    "generateClassificationReport( y_train, y_pred)\n",
    "\n",
    "# Make predictions and evaluate the model with the testing set\n",
    "print(\"\\n------Testing Set------\")\n",
    "y_pred = knn.predict(X_test)\n",
    "generateClassificationReport( y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation With Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix for Random Forest\n",
    "plot_confusion_matrix(y_test, rf.predict(X_test), \"Random Forest Confusion Matrix\")\n",
    "# Plot confusion matrix for SVM\n",
    "plot_confusion_matrix(y_test, svm.predict(X_test), \"SVM Confusion Matrix\")\n",
    "# Plot confusion matrix for KNN\n",
    "plot_confusion_matrix(y_test, knn.predict(X_test), \"KNN Confusion Matrix\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
